{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obligatorio 2 - Big Data Science\n",
    "\n",
    "Integrantes del grupo: Federico Abdo, Juan Cruz Carrau, Joaquín Fernández\n",
    "\n",
    "Debajo de cada pregunta o tarea incluya las celdas necesarias para desarrolar la respuesta. Puede usar una o varias celdas de código o mark down (https://www.datacamp.com/community/tutorials/markdown-in-jupyter-notebook)\n",
    "\n",
    "Para entregar, renombrar este notebook como \"Obligatorio 2 - Apellido1 - Apellido 2 - Apellido 3\" con los apellidos de los miembros del grupo. Un solo integrante del grupo debe realizar la entrega. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cargar los datos del Obligatorio 1, de entrenamiento (.data) y validación (.test) en spark dataframes (distintos). Los nombres de las columnas deben corresponder a los especificados en \"Attribute Information\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "sc.stop()\n",
    "sc = SparkContext('local', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-IPN67O4:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=test>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "spark = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x2458b8a0610>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# Schema de los dataset\n",
    "schema = StructType([\n",
    "    StructField(name='age', dataType=IntegerType(), nullable=False),\n",
    "    StructField(name='workclass', dataType=StringType(), nullable=False),\n",
    "    StructField(name='fnlwgt', dataType=StringType(), nullable=False), # Se pone en tipo string porque al ponerlo en tipo Integer o Long carga la columna con valores null\n",
    "    StructField(name='education', dataType=StringType(), nullable=False),\n",
    "    StructField(name='education_num', dataType=StringType(), nullable=False), # Mismo problema que en la columna 'fnlwgt'\n",
    "    StructField(name='marital-status', dataType=StringType(), nullable=False),\n",
    "    StructField(name='occupation', dataType=StringType(), nullable=False),\n",
    "    StructField(name='relationship', dataType=StringType(), nullable=False),\n",
    "    StructField(name='race', dataType=StringType(), nullable=False),\n",
    "    StructField(name='sex', dataType=StringType(), nullable=False),\n",
    "    StructField(name='capital_gain', dataType=StringType(), nullable=False), # Mismo problema que en la columna 'fnlwgt'\n",
    "    StructField(name='capital_loss', dataType=StringType(), nullable=False), # Mismo problema que en la columna 'fnlwgt'\n",
    "    StructField(name='hours_per_week', dataType=StringType(), nullable=False), # Mismo problema que en la columna 'fnlwgt'\n",
    "    StructField(name='native_country', dataType=StringType(), nullable=False),\n",
    "    StructField(name='income', dataType=StringType(), nullable=False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult = spark.read.csv(\"adult.data\", header=True, schema=schema)\n",
    "df_test = spark.read.csv(\"adult.test\", header=True, schema=schema) # sacamos el punto del archivo adult.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+-------+-------------+-------------+--------------------+------------------+--------------+------+-------+------------+------------+--------------+--------------+------+\n",
      "|age|        workclass| fnlwgt|    education|education_num|      marital-status|        occupation|  relationship|  race|    sex|capital_gain|capital_loss|hours_per_week|native_country|income|\n",
      "+---+-----------------+-------+-------------+-------------+--------------------+------------------+--------------+------+-------+------------+------------+--------------+--------------+------+\n",
      "| 50| Self-emp-not-inc|  83311|    Bachelors|           13|  Married-civ-spouse|   Exec-managerial|       Husband| White|   Male|           0|           0|            13| United-States| <=50K|\n",
      "| 38|          Private| 215646|      HS-grad|            9|            Divorced| Handlers-cleaners| Not-in-family| White|   Male|           0|           0|            40| United-States| <=50K|\n",
      "| 53|          Private| 234721|         11th|            7|  Married-civ-spouse| Handlers-cleaners|       Husband| Black|   Male|           0|           0|            40| United-States| <=50K|\n",
      "| 28|          Private| 338409|    Bachelors|           13|  Married-civ-spouse|    Prof-specialty|          Wife| Black| Female|           0|           0|            40|          Cuba| <=50K|\n",
      "| 37|          Private| 284582|      Masters|           14|  Married-civ-spouse|   Exec-managerial|          Wife| White| Female|           0|           0|            40| United-States| <=50K|\n",
      "| 49|          Private| 160187|          9th|            5| Married-spouse-a...|     Other-service| Not-in-family| Black| Female|           0|           0|            16|       Jamaica| <=50K|\n",
      "| 52| Self-emp-not-inc| 209642|      HS-grad|            9|  Married-civ-spouse|   Exec-managerial|       Husband| White|   Male|           0|           0|            45| United-States|  >50K|\n",
      "| 31|          Private|  45781|      Masters|           14|       Never-married|    Prof-specialty| Not-in-family| White| Female|       14084|           0|            50| United-States|  >50K|\n",
      "| 42|          Private| 159449|    Bachelors|           13|  Married-civ-spouse|   Exec-managerial|       Husband| White|   Male|        5178|           0|            40| United-States|  >50K|\n",
      "| 37|          Private| 280464| Some-college|           10|  Married-civ-spouse|   Exec-managerial|       Husband| Black|   Male|           0|           0|            80| United-States|  >50K|\n",
      "+---+-----------------+-------+-------------+-------------+--------------------+------------------+--------------+------+-------+------------+------------+--------------+--------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_adult.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+-------+-------------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+--------------+--------------+------+\n",
      "|age|        workclass| fnlwgt|    education|education_num|     marital-status|        occupation|  relationship|  race|    sex|capital_gain|capital_loss|hours_per_week|native_country|income|\n",
      "+---+-----------------+-------+-------------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+--------------+--------------+------+\n",
      "| 38|          Private|  89814|      HS-grad|            9| Married-civ-spouse|   Farming-fishing|       Husband| White|   Male|           0|           0|            50| United-States| <=50K|\n",
      "| 28|        Local-gov| 336951|   Assoc-acdm|           12| Married-civ-spouse|   Protective-serv|       Husband| White|   Male|           0|           0|            40| United-States|  >50K|\n",
      "| 44|          Private| 160323| Some-college|           10| Married-civ-spouse| Machine-op-inspct|       Husband| Black|   Male|        7688|           0|            40| United-States|  >50K|\n",
      "| 18|                ?| 103497| Some-college|           10|      Never-married|                 ?|     Own-child| White| Female|           0|           0|            30| United-States| <=50K|\n",
      "| 34|          Private| 198693|         10th|            6|      Never-married|     Other-service| Not-in-family| White|   Male|           0|           0|            30| United-States| <=50K|\n",
      "| 29|                ?| 227026|      HS-grad|            9|      Never-married|                 ?|     Unmarried| Black|   Male|           0|           0|            40| United-States| <=50K|\n",
      "| 63| Self-emp-not-inc| 104626|  Prof-school|           15| Married-civ-spouse|    Prof-specialty|       Husband| White|   Male|        3103|           0|            32| United-States|  >50K|\n",
      "| 24|          Private| 369667| Some-college|           10|      Never-married|     Other-service|     Unmarried| White| Female|           0|           0|            40| United-States| <=50K|\n",
      "| 55|          Private| 104996|      7th-8th|            4| Married-civ-spouse|      Craft-repair|       Husband| White|   Male|           0|           0|            10| United-States| <=50K|\n",
      "| 65|          Private| 184454|      HS-grad|            9| Married-civ-spouse| Machine-op-inspct|       Husband| White|   Male|        6418|           0|            40| United-States|  >50K|\n",
      "+---+-----------------+-------+-------------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+--------------+--------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Seleccionar un conjunto relevante de 5 atributos y crear un Spark Pipeline en el que el estimator sea un DecisionTreeClassifier (https://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-classifier). Puede utilizar libremente los transformers/estimators de Spark para realizar ingeniería de atributos (StringIndexer, OneHotEncoding, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos = [\"age\", \"sex\", \"occupation\", \"education\", \"workclass\"]\n",
    "\n",
    "#Primero hay que bucketizar la edad. La separamos en 3 buckets. \n",
    "\n",
    "def calculo_de_buckets(df, cantidad_buckets, columna):\n",
    "    df.createOrReplaceTempView(\"df_view\")\n",
    "    instancias_totales = spark.sql('''SELECT count(*) as count FROM df_view''').first()['count']\n",
    "    instancias_en_bucket = instancias_totales / cantidad_buckets\n",
    "    \n",
    "    limites = []\n",
    "    ultimo_limite_superior = None\n",
    "    for limit in range(0, instancias_totales - 1, round(instancias_en_bucket)): # se pone un -1 porque instancias totales es el count pero queremos llegar hasta el indice        \n",
    "        query = spark.sql(f'''SELECT {columna} FROM df_view ORDER BY 1 asc''').collect()\n",
    "        limite_inferior = query[limit][columna]\n",
    "        \n",
    "        if(ultimo_limite_superior is not None):\n",
    "            if ultimo_limite_superior == limite_inferior:\n",
    "                limite_inferior += 1;\n",
    "        \n",
    "        limite = [limite_inferior, query[limit + round(instancias_en_bucket)][columna]]\n",
    "        limites.append(limite)\n",
    "        \n",
    "        ultimo_limite_superior = query[limit + round(instancias_en_bucket)][columna]\n",
    "\n",
    "    return limites\n",
    "\n",
    "limites = calculo_de_buckets(df_adult, 3, \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def age_bucket_udf(age):\n",
    "    indexes = range(len(limites))\n",
    "    for index, limite in zip(indexes, limites):\n",
    "        if age in range(limite[0], limite[1] + 1):    #Se agrega el +1 para hacer el range inclusivo superiormente\n",
    "            return str(index)\n",
    "\n",
    "age_udf = F.udf(age_bucket_udf, StringType())\n",
    "\n",
    "df_adult_bucketized = df_adult.withColumn(\"ageBucket\", age_udf(F.col(\"age\")))\n",
    "df_test_bucketized = df_test.withColumn(\"ageBucket\", age_udf(F.col(\"age\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexers(columnas):\n",
    "    \n",
    "    list_indexer = []\n",
    "    \n",
    "    for columna in columnas:\n",
    "        list_indexer.append(StringIndexer(inputCol=columna, outputCol=columna+\"Index\"))\n",
    "    \n",
    "    return list_indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline(\n",
    "                categoricalColumns=[\"sex\", \"occupation\", \"education\", \"workclass\", \"ageBucket\"],\n",
    "                labelCol='income',\n",
    "                thresholds=None\n",
    "                ):\n",
    "    stages = []\n",
    "\n",
    "    stages += get_indexers([labelCol])\n",
    "\n",
    "    stages += get_indexers(categoricalColumns)\n",
    "\n",
    "    assembler_input = [c + \"Index\" for c in categoricalColumns]\n",
    "\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=assembler_input,\n",
    "        outputCol=\"features\")\n",
    "\n",
    "    stages += [assembler]\n",
    "    \n",
    "    dt = DecisionTreeClassifier(labelCol=labelCol+\"Index\", featuresCol=\"features\")\n",
    "    \n",
    "    if thresholds:\n",
    "        dt.setThresholds(thresholds)\n",
    "\n",
    "    stages += [dt]\n",
    "    \n",
    "    return Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = get_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Hacer el fit del pipeline con los datos de entrenamiento. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = df_adult_bucketized\n",
    "testData = df_test_bucketized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5d58c0b896ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    159\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pyspark\\ml\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    112\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# must be an Estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    159\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \"\"\"\n\u001b[0;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1303\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1200\u001b[1;33m             \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Answer received: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = predictions\n",
    "\n",
    "df_.createOrReplaceTempView('df_')\n",
    "\n",
    "df_aciertos = spark.sql(\"\"\"\n",
    "    SELECT income, prediction, count(*)\n",
    "    FROM df_\n",
    "    GROUP BY 1, 2\n",
    "\"\"\")\n",
    "\n",
    "df_aciertos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATRIZ DE CONFUSION\n",
    "import pandas as pd\n",
    "pd.DataFrame([[1109, 535], [2737, 11899]], columns=['POSITIVO ACTUAL', 'NEGATIVO ACTUAL'], index = ['POSITIVO PREDECIDO', 'NEGATIVO PREDECIDO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Graficar la curva ROC utilizando los datos de validación (sin usar el paquete de evluación de Spark pyspark.ml.evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = df_adult_bucketized\n",
    "testData = df_test_bucketized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tpr_and_fpr(prediction):\n",
    "    \n",
    "    df_ = predictions\n",
    "\n",
    "    df_.createOrReplaceTempView('df_')\n",
    "\n",
    "    df_aciertos = spark.sql(\"\"\"\n",
    "        SELECT income, prediction, count(*) as count\n",
    "        FROM df_\n",
    "        GROUP BY 1, 2\n",
    "    \"\"\")\n",
    "    \n",
    "    tp = df_aciertos.where('income = \" >50K\" and prediction = 1.0').first()['count'] if df_aciertos.where('income = \" >50K\" and prediction = 1.0').count() > 0 else 0\n",
    "    \n",
    "    fn = df_aciertos.where('income = \" >50K\" and prediction = \"0.0\"').first()['count'] if df_aciertos.where('income = \" >50K\" and prediction = \"0.0\"').count() > 0 else 0\n",
    "    \n",
    "    \n",
    "    fp = df_aciertos.where('income = \" <=50K\" and prediction = 1.0').first()['count'] if df_aciertos.where('income = \" <=50K\" and prediction = 1.0').count() > 0 else 0\n",
    "    \n",
    "    \n",
    "    tn = df_aciertos.where('income = \" <=50K\" and prediction = 0.0').first()['count'] if df_aciertos.where('income = \" <=50K\" and prediction = 0.0').count() > 0 else 0\n",
    "    \n",
    "        \n",
    "    tpr = tp/(tp + fn)\n",
    "    \n",
    "    fpr = fp/(tn + fp)\n",
    "    \n",
    "    return (tpr, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tpr_and_fpr(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = range(0, 105, 5)\n",
    "\n",
    "values = []\n",
    "\n",
    "for t in thresholds:\n",
    "    t = t/100\n",
    "    print(t)\n",
    "    \n",
    "    pipeline = get_pipeline(thresholds=[1-t, t])\n",
    "    \n",
    "    model = pipeline.fit(trainingData)\n",
    "    \n",
    "    predictions = model.transform(testData)\n",
    "    \n",
    "    tpr, fpr = get_tpr_and_fpr(predictions)\n",
    "    \n",
    "    values.append([t, [tpr, fpr]])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([(p,tpr,fpr) for (p,(tpr,fpr)) in values], columns=['p', 'tpr', 'fpr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(style='.-',x='fpr',y='tpr', \n",
    "        title=\"ROC (Receiver Operating Characteristic) Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Escribir dos funciones train() y predict() que creen el arbol de acuerdo a la metodología vista en clase (utilizando entropía como métrica de homogeneidad de clases).\n",
    "```\n",
    "def train(train_dataframe):\n",
    "    '''\n",
    "    @return devuelve una estructura de datos que representa el árbol de decision\n",
    "    '''\n",
    "     pass        \n",
    "```\n",
    "\n",
    "```\n",
    "def predict(tree, train_dataframe)\n",
    "    '''\n",
    "    @param tree la estructura de datos que representa el árbol de decisión.\n",
    "    @ return un dataframe con todos los datos de train_dataframe con una columna adicional que representa la probabilidad de que el income sea >50K. \n",
    "    '''\n",
    "    pass\n",
    "```    \n",
    "Ejemplo de uso:\n",
    "\n",
    "```\n",
    "tree = train(train_dataframe)\n",
    "predictions_df = predict(tree, train_dataframe)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def entropy(probabs):\n",
    "    return -sum([ p * math.log(p,2) for p in probabs if p != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_entropy(df, col):\n",
    "    \"\"\"Calculamos la entropy de una columna\"\"\"\n",
    "    \n",
    "    ncol = df.select(col).distinct().collect()\n",
    "    ncol = [row[col] for  row in ncol]\n",
    "    \n",
    "    total = df.count()\n",
    "    \n",
    "    prob_valor = {}\n",
    "    \n",
    "    entropy_valor = {}\n",
    "    \n",
    "    for valor in ncol:\n",
    "        ntmp = df.select(col).where(f'{col} = \"{valor}\"').count()\n",
    "        \n",
    "        prob_valor[valor] = ntmp/total\n",
    "        \n",
    "        ntmp_pos = df.select(col).where(f'{col} = \"{valor}\" and income = \" >50K\"').count()\n",
    "        \n",
    "        prob_pos = ntmp_pos/ntmp\n",
    "        \n",
    "        prob_neg = 1 - prob_pos\n",
    "        \n",
    "        entropy_ = entropy([prob_pos, prob_neg])\n",
    "        \n",
    "        entropy_valor[valor] = entropy_\n",
    "    \n",
    "    suma_ponderada = 0\n",
    "    \n",
    "    for valor in ncol:\n",
    "        suma_ponderada += prob_valor[valor] * entropy_valor[valor]\n",
    "    \n",
    "    return suma_ponderada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_split(df, root, categorias):\n",
    "    \n",
    "    print(vars(root))\n",
    "    \n",
    "    if len(categorias) == 0:\n",
    "        \n",
    "        c1 = df.select('income').where('income = \" >50K\"').count()\n",
    "        \n",
    "        c2 = df.select('income').where('income =  \" <=50K\"').count()\n",
    "        \n",
    "        root.prediccion = \">50K\" if c1>c2 else \"<=50K\"\n",
    "        \n",
    "        return\n",
    "    \n",
    "    categoria_entropy = {}\n",
    "    \n",
    "    for categoria in categorias:\n",
    "        categoria_entropy[categoria] = get_feature_entropy(df, categoria)\n",
    "    \n",
    "    categoria_minima = min(categoria_entropy, key=categoria_entropy.get)\n",
    "    \n",
    "    if root.columna_hijos is None: ## Solamente entra en el root\n",
    "        root.columna_hijos = categoria_minima\n",
    "    \n",
    "    valores_categoria = [valores[categoria_minima] for valores in df.select(categoria_minima).distinct().collect()]\n",
    "    \n",
    "    for valor in valores_categoria:\n",
    "        \n",
    "        root.hijos[valor] = Nodo(valor=valor, padre=root, columna_hijos=categoria_minima)\n",
    "        \n",
    "        df_ = df.where(f'{categoria_minima} = \"{valor}\"').drop(categoria_minima)\n",
    "        \n",
    "        categorias_aux = categorias.copy()\n",
    "        categorias_aux.remove(categoria_minima)\n",
    "        \n",
    "        make_split(df_, root.hijos[valor], categorias_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nodo:\n",
    "    def __init__(self, valor, padre, prediccion=None, hijos=None, columna_hijos = None):\n",
    "        self.valor = valor\n",
    "        \n",
    "        if padre == 'root':\n",
    "            self.padre = None\n",
    "        else:\n",
    "            self.padre = padre\n",
    "        \n",
    "        self.hijos = {} if not hijos else hijos\n",
    "        \n",
    "        self.columna_hijos = columna_hijos\n",
    "        \n",
    "        self.prediccion = prediccion\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataframe, columns=[\"sex\", \"occupation\", \"education\", \"workclass\", \"ageBucket\"]):\n",
    "    '''\n",
    "    @return devuelve una estructura de datos que representa el árbol de decision\n",
    "    '''\n",
    "        \n",
    "    arbol = Nodo(None, 'root')\n",
    "    make_split(df=train_dataframe, root=arbol, categorias=columns)\n",
    "    \n",
    "    return arbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version dinamica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte se intento hacer que una funcion pueda tomar una cantidad variable de columnas pero no se pudo resolver como pasarle un diccionario a un udf.\n",
    "Se buscaron metodos y aparecieron algunas soluciones pero ninguna que se entiendiera o se pudiera utilizar.\n",
    "Por lo tanto se expone el codigo nada mas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valor': None, 'padre': None, 'hijos': {}, 'columna_hijos': None, 'prediccion': None}\n",
      "{'valor': ' Farming-fishing', 'padre': <__main__.Nodo object at 0x0000024596179EE0>, 'hijos': {}, 'columna_hijos': 'occupation', 'prediccion': None}\n",
      "{'valor': ' State-gov', 'padre': <__main__.Nodo object at 0x0000024596482DF0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Federal-gov', 'padre': <__main__.Nodo object at 0x0000024596482DF0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-not-inc', 'padre': <__main__.Nodo object at 0x0000024596482DF0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Local-gov', 'padre': <__main__.Nodo object at 0x0000024596482DF0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Private', 'padre': <__main__.Nodo object at 0x0000024596482DF0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-inc', 'padre': <__main__.Nodo object at 0x0000024596482DF0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Without-pay', 'padre': <__main__.Nodo object at 0x0000024596482DF0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Handlers-cleaners', 'padre': <__main__.Nodo object at 0x0000024596179EE0>, 'hijos': {}, 'columna_hijos': 'occupation', 'prediccion': None}\n",
      "{'valor': ' State-gov', 'padre': <__main__.Nodo object at 0x0000024596561670>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Federal-gov', 'padre': <__main__.Nodo object at 0x0000024596561670>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-not-inc', 'padre': <__main__.Nodo object at 0x0000024596561670>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Local-gov', 'padre': <__main__.Nodo object at 0x0000024596561670>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Private', 'padre': <__main__.Nodo object at 0x0000024596561670>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-inc', 'padre': <__main__.Nodo object at 0x0000024596561670>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Without-pay', 'padre': <__main__.Nodo object at 0x0000024596561670>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Prof-specialty', 'padre': <__main__.Nodo object at 0x0000024596179EE0>, 'hijos': {}, 'columna_hijos': 'occupation', 'prediccion': None}\n",
      "{'valor': ' State-gov', 'padre': <__main__.Nodo object at 0x0000024596561310>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Federal-gov', 'padre': <__main__.Nodo object at 0x0000024596561310>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-not-inc', 'padre': <__main__.Nodo object at 0x0000024596561310>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Local-gov', 'padre': <__main__.Nodo object at 0x0000024596561310>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Private', 'padre': <__main__.Nodo object at 0x0000024596561310>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-inc', 'padre': <__main__.Nodo object at 0x0000024596561310>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Adm-clerical', 'padre': <__main__.Nodo object at 0x0000024596179EE0>, 'hijos': {}, 'columna_hijos': 'occupation', 'prediccion': None}\n",
      "{'valor': ' State-gov', 'padre': <__main__.Nodo object at 0x0000024597785250>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Federal-gov', 'padre': <__main__.Nodo object at 0x0000024597785250>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-not-inc', 'padre': <__main__.Nodo object at 0x0000024597785250>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Local-gov', 'padre': <__main__.Nodo object at 0x0000024597785250>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Private', 'padre': <__main__.Nodo object at 0x0000024597785250>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-inc', 'padre': <__main__.Nodo object at 0x0000024597785250>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Without-pay', 'padre': <__main__.Nodo object at 0x0000024597785250>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Exec-managerial', 'padre': <__main__.Nodo object at 0x0000024596179EE0>, 'hijos': {}, 'columna_hijos': 'occupation', 'prediccion': None}\n",
      "{'valor': ' State-gov', 'padre': <__main__.Nodo object at 0x0000024596467A00>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Federal-gov', 'padre': <__main__.Nodo object at 0x0000024596467A00>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-not-inc', 'padre': <__main__.Nodo object at 0x0000024596467A00>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Local-gov', 'padre': <__main__.Nodo object at 0x0000024596467A00>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Private', 'padre': <__main__.Nodo object at 0x0000024596467A00>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-inc', 'padre': <__main__.Nodo object at 0x0000024596467A00>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Craft-repair', 'padre': <__main__.Nodo object at 0x0000024596179EE0>, 'hijos': {}, 'columna_hijos': 'occupation', 'prediccion': None}\n",
      "{'valor': ' State-gov', 'padre': <__main__.Nodo object at 0x00000245965773D0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Federal-gov', 'padre': <__main__.Nodo object at 0x00000245965773D0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-not-inc', 'padre': <__main__.Nodo object at 0x00000245965773D0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Local-gov', 'padre': <__main__.Nodo object at 0x00000245965773D0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Private', 'padre': <__main__.Nodo object at 0x00000245965773D0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-inc', 'padre': <__main__.Nodo object at 0x00000245965773D0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Without-pay', 'padre': <__main__.Nodo object at 0x00000245965773D0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Sales', 'padre': <__main__.Nodo object at 0x0000024596179EE0>, 'hijos': {}, 'columna_hijos': 'occupation', 'prediccion': None}\n",
      "{'valor': ' State-gov', 'padre': <__main__.Nodo object at 0x00000245964676D0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Federal-gov', 'padre': <__main__.Nodo object at 0x00000245964676D0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-not-inc', 'padre': <__main__.Nodo object at 0x00000245964676D0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Local-gov', 'padre': <__main__.Nodo object at 0x00000245964676D0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Private', 'padre': <__main__.Nodo object at 0x00000245964676D0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-inc', 'padre': <__main__.Nodo object at 0x00000245964676D0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' ?', 'padre': <__main__.Nodo object at 0x0000024596179EE0>, 'hijos': {}, 'columna_hijos': 'occupation', 'prediccion': None}\n",
      "{'valor': ' ?', 'padre': <__main__.Nodo object at 0x000002459778F790>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Never-worked', 'padre': <__main__.Nodo object at 0x000002459778F790>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Tech-support', 'padre': <__main__.Nodo object at 0x0000024596179EE0>, 'hijos': {}, 'columna_hijos': 'occupation', 'prediccion': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valor': ' State-gov', 'padre': <__main__.Nodo object at 0x00000245964675B0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Federal-gov', 'padre': <__main__.Nodo object at 0x00000245964675B0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-not-inc', 'padre': <__main__.Nodo object at 0x00000245964675B0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Local-gov', 'padre': <__main__.Nodo object at 0x00000245964675B0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Private', 'padre': <__main__.Nodo object at 0x00000245964675B0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-inc', 'padre': <__main__.Nodo object at 0x00000245964675B0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Transport-moving', 'padre': <__main__.Nodo object at 0x0000024596179EE0>, 'hijos': {}, 'columna_hijos': 'occupation', 'prediccion': None}\n",
      "{'valor': ' State-gov', 'padre': <__main__.Nodo object at 0x000002459618FDC0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Federal-gov', 'padre': <__main__.Nodo object at 0x000002459618FDC0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-not-inc', 'padre': <__main__.Nodo object at 0x000002459618FDC0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Local-gov', 'padre': <__main__.Nodo object at 0x000002459618FDC0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Private', 'padre': <__main__.Nodo object at 0x000002459618FDC0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-inc', 'padre': <__main__.Nodo object at 0x000002459618FDC0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Without-pay', 'padre': <__main__.Nodo object at 0x000002459618FDC0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Protective-serv', 'padre': <__main__.Nodo object at 0x0000024596179EE0>, 'hijos': {}, 'columna_hijos': 'occupation', 'prediccion': None}\n",
      "{'valor': ' State-gov', 'padre': <__main__.Nodo object at 0x0000024597DDF790>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Federal-gov', 'padre': <__main__.Nodo object at 0x0000024597DDF790>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-not-inc', 'padre': <__main__.Nodo object at 0x0000024597DDF790>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Local-gov', 'padre': <__main__.Nodo object at 0x0000024597DDF790>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Private', 'padre': <__main__.Nodo object at 0x0000024597DDF790>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-inc', 'padre': <__main__.Nodo object at 0x0000024597DDF790>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Armed-Forces', 'padre': <__main__.Nodo object at 0x0000024596179EE0>, 'hijos': {}, 'columna_hijos': 'occupation', 'prediccion': None}\n",
      "{'valor': ' Federal-gov', 'padre': <__main__.Nodo object at 0x00000245965C0A30>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Machine-op-inspct', 'padre': <__main__.Nodo object at 0x0000024596179EE0>, 'hijos': {}, 'columna_hijos': 'occupation', 'prediccion': None}\n",
      "{'valor': ' State-gov', 'padre': <__main__.Nodo object at 0x00000245974B1610>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Federal-gov', 'padre': <__main__.Nodo object at 0x00000245974B1610>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-not-inc', 'padre': <__main__.Nodo object at 0x00000245974B1610>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Local-gov', 'padre': <__main__.Nodo object at 0x00000245974B1610>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Private', 'padre': <__main__.Nodo object at 0x00000245974B1610>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-inc', 'padre': <__main__.Nodo object at 0x00000245974B1610>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Without-pay', 'padre': <__main__.Nodo object at 0x00000245974B1610>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Other-service', 'padre': <__main__.Nodo object at 0x0000024596179EE0>, 'hijos': {}, 'columna_hijos': 'occupation', 'prediccion': None}\n",
      "{'valor': ' State-gov', 'padre': <__main__.Nodo object at 0x00000245974B1F40>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Federal-gov', 'padre': <__main__.Nodo object at 0x00000245974B1F40>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-not-inc', 'padre': <__main__.Nodo object at 0x00000245974B1F40>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Local-gov', 'padre': <__main__.Nodo object at 0x00000245974B1F40>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Private', 'padre': <__main__.Nodo object at 0x00000245974B1F40>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Self-emp-inc', 'padre': <__main__.Nodo object at 0x00000245974B1F40>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Without-pay', 'padre': <__main__.Nodo object at 0x00000245974B1F40>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n",
      "{'valor': ' Priv-house-serv', 'padre': <__main__.Nodo object at 0x0000024596179EE0>, 'hijos': {}, 'columna_hijos': 'occupation', 'prediccion': None}\n",
      "{'valor': ' Private', 'padre': <__main__.Nodo object at 0x00000245974B87C0>, 'hijos': {}, 'columna_hijos': 'workclass', 'prediccion': None}\n"
     ]
    }
   ],
   "source": [
    "arbol = train(df_adult_bucketized, columns=df_adult_bucketized.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_arbol(arbol, tab):\n",
    "    \n",
    "    if arbol.prediccion is None:\n",
    "        print('|', tab*'►', arbol.valor)\n",
    "        for _, hijo in arbol.hijos.items():\n",
    "            imprimir_arbol(hijo, tab+1)\n",
    "    else:\n",
    "        print('|', tab*'--', arbol.valor, '►', arbol.prediccion)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprime el arbol resultante\n",
    "imprimir_arbol(arbol, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version dinamica (no fucionante)\n",
    "def predict(tree, train_dataframe, columns=[\"sex\", \"occupation\", \"education\", \"workclass\", \"ageBucket\"]):\n",
    "    '''\n",
    "    @param tree la estructura de datos que representa el árbol de decisión.\n",
    "    @ return un dataframe con todos los datos de train_dataframe con una columna adicional que representa la probabilidad de que el income sea >50K. \n",
    "    '''\n",
    "    \n",
    "    def give_prediction(columns):\n",
    "        \n",
    "        kwargs={}\n",
    "        for col_name, col in zip(columns_name, columns):\n",
    "            kwargs[col_name] = col\n",
    "#         for key, value in kwargs:\n",
    "#             kwargs[key] = kwargs[key][key]\n",
    "        \n",
    "        #p.append(str(kwargs))\n",
    "        \n",
    "        nodo_actual = tree.copy()\n",
    "        \n",
    "        while(nodo_actual.prediccion is None):\n",
    "            \n",
    "            if nodo_actual.hijos.get(kwarg.get(nodo_actual.columna_hijos)) is not None:\n",
    "                nodo_actual = nodo_actual.hijos.get(kwarg.get(nodo_actual.columna_hijos))\n",
    "            else:\n",
    "                return \"\";\n",
    "        \n",
    "        return nodo_actual.prediccion\n",
    "        \n",
    "    \n",
    "    \n",
    "    predict_udf = F.udf(give_prediction, StringType())\n",
    "\n",
    "    return train_dataframe.withColumn(\"prediction\", predict_udf(F.lit([F.col(column) for column in columns])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version hardcoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que no se pudo hacer la version dinamica, se intento hacer una version hardcodeada. Debajo se puede ver la version que tiene las 5 columnas que estabamos utilizando, pero como esta version demora muchas horas para hacer un simple testeo se tuvo que hacer una con menos columnas.\n",
    "De todas formas por algun error que no se pudo arreglar, al hacer el .show() no aparece el resultado esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version hardcoded (de 5 columnas)\n",
    "import copy\n",
    "def predict(tree, train_dataframe):\n",
    "    '''\n",
    "    @param tree la estructura de datos que representa el árbol de decisión.\n",
    "    @ return un dataframe con todos los datos de train_dataframe con una columna adicional que representa la probabilidad de que el income sea >50K. \n",
    "    '''\n",
    "    \n",
    "    def give_prediction(sex, occupation, education, workclass, ageBucket):\n",
    "                \n",
    "        kwarg = {\"sex\":sex, \"occupation\":occupation,  \"education\": education, \"workclass\": workclass, \"ageBucket\": ageBucket}    \n",
    "        \n",
    "        nodo_actual = copy.deepcopy(tree)\n",
    "        \n",
    "        while(nodo_actual.prediccion is None):\n",
    "            \n",
    "            if nodo_actual.hijos.get(kwarg.get(nodo_actual.columna_hijos)) is not None:\n",
    "                nodo_actual = nodo_actual.hijos.get(kwarg.get(nodo_actual.columna_hijos))\n",
    "            else:\n",
    "                return \"\";\n",
    "        \n",
    "        return nodo_actual.prediccion\n",
    "        \n",
    "    \n",
    "    \n",
    "    predict_udf = F.udf(give_prediction, StringType())\n",
    "\n",
    "    return train_dataframe.withColumn(\"prediction\", predict_udf(F.col(\"sex\"), F.col(\"occupation\"),F.col(\"education\"), F.col(\"workclass\"),F.col(\"ageBucket\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version hardcoded (2 columnas)\n",
    "import copy\n",
    "def predict(tree, train_dataframe):\n",
    "    '''\n",
    "    @param tree la estructura de datos que representa el árbol de decisión.\n",
    "    @ return un dataframe con todos los datos de train_dataframe con una columna adicional que representa la probabilidad de que el income sea >50K. \n",
    "    '''\n",
    "    \n",
    "    def give_prediction(occupation, workclass):\n",
    "        kwarg = {\"occupation\":occupation,\"workclass\": workclass}    \n",
    "        nodo_actual = copy.deepcopy(tree)\n",
    "        \n",
    "        while(nodo_actual.prediccion is None):\n",
    "            \n",
    "            if nodo_actual.hijos.get(kwarg.get(nodo_actual.columna_hijos)) is not None:\n",
    "                nodo_actual = nodo_actual.hijos.get(kwarg.get(nodo_actual.columna_hijos))\n",
    "            else:\n",
    "                return \"\"\n",
    "        \n",
    "        return nodo_actual.prediccion\n",
    "    \n",
    "    predict_udf = F.udf(give_prediction, StringType())\n",
    "\n",
    "    return train_dataframe.withColumn(\"prediction\", predict_udf(F.col(\"occupation\"), F.col(\"workclass\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = predict(arbol, df_adult_bucketized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>[Extra credit y alumnos masters]</i>\n",
    "    \n",
    "5.  Mejorar la implementación de su algoritmo evitando hacer el split cuando no se logra un mínimo de Information Gain ( https://en.wikipedia.org/wiki/Information_gain_in_decision_trees   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
